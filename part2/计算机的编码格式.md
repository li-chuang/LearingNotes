1.ASCII
  电脑刚一出先，就面对这使用字符的问题，不过在计算机发明之初，基本上只考虑了美国的需求。
  于是美国就规定了128个字符的二进制表示方法，这个方法是一个标准，称为ASCII编码，全称
  是American Standard Code for Information Interchange，美国信息互换标准代码

  关于ASCII，我们需要知道这么几点：
  i.ASCII的设计之初，根本就没有想过别国的需求，因为当时计算机的发展也没有现在这么国际化，
    所以设计之初，只考虑了美国的需求；
  ii.计算机存储的最小单位是byte，有八位，而ASCII总共设计了127个字符，用后7位就可以表示，最高位设置为0
  iii.ASCII码规定了从0到127，每个数字代表什么含义，如48代表‘0’，65代表‘A’,97代表‘a’ 


2.ASCII对美国是够用了，但对其他的国家却是不够的，例如汉字就有上万个。于是各国为了自己的使用需求，开发了各种各样的编码方式来
  表示自己国家的字符。同时为了保持与ASCII的兼容性，一般都将最高位设置为1。也就是说，当最高位是0时，表示ASCII码，当为1时就是
  各个国家自己的字符编码 


3.ISO 8859-1
  ISO 8859-1又被称作Latin-1，它也是使用一个字节表示一个字符，其中0到127与ASCII一样，128到255规定了不同的含义，
  其中包括法语、德语字符等，都是一些西欧字符

  关于ISO 8859-1，我们需要知道这么几点：
  i.ISO 8859-1使用了一个字节中全部8位，即使用了单字节的全部空间，所以在支持ISO 8859-1的系统中传输和存储其他任何编码的字节流
    都不会被抛弃。换言之，把其他任何编码的字节流当作ISO-8859-1编码看待都没有问题
  ii.虽然ISO 8859-1也算是抢到了先机，但是毕竟空间有限，也不容易扩展，于是有些重要的符号不在其中，比如欧元符号，这是因为欧元
    出现得比较晚，此时已经没有办法扩展了
  iii.英语字符用ASCII编码即可搞定，完全用不到此编码的后半部分，但英语还是标明为ISO/IEC 8859-1编码

  
4.Windows-1252
  ISO 8859-1虽然号称是标准，用于西欧国家，但它连欧元(€) 这个符号都没有，因为欧元比较晚，而标准比较早。实际使用中更为广泛的
  是Windows-1252编码，这个编码与ISO8859-1基本是一样的，区别 只在于数字128到159，Windows-1252使用其中的一些数字表示可打印字符

  这个编码中加入了欧元符号以及一些其他常用的字符。基本上可以认为，ISO 8859-1已被Windows-1252取代，在很多应用程序中，
  即使文件声明它采用的是ISO 8859-1编码，解析的时候依然被当做Windows-1252编码。

  HTML5 甚至明确规定，如果文件声明的是ISO 8859-1编码，它应该被看做Windows-1252编码。为什么要这样呢？因为大部分人
  搞不清楚ISO 8859-1和Windows-1252的区别，当他说ISO 8859-1的时候，其实他实际指的是Windows-1252，所以标准干脆就这么强制了。

  关于Windows-1252编码，我们需要知道以下几点：
  i.此编码和ISO 8859-1占用的空间一样，都是一个字节，用8位表示，两者之间有继承关系，Windows-1252经过深度优化后基本
    取代了ISO 8859-1
  ii.即使声明的是ISO 8859-1，但指向的还是Windows-1252，这一点是强制性的


5.GB2312
  一个字节有8位，有256个值，对英美等拉丁系的国家来说，显示字符是够用了，但对中文来说，常用的汉字就有7000多个，一个字节显然是不够的，
  于是就诞生了GB2312，这是中文的第一个标准，主要针对的是简体中文常见字符，包括约7000个汉字，不包括一些罕用词，不包括繁体字。
  
  关于GB2312编码，我们需要知道以下几点：
  i.GB2312固定使用两个字节表示汉字，在这两个字节中，最高位都是1。如果最高位是0，则认为是ASCII字符
  ii.在这两个字节中，第一个字节（高位字节）范围是0xA1-0xF7，第二个字节（低位字节）范围是0xA1-0xFE
  iii.字符串“李闯”和“Àî´³”，在转换为字节流进行传递的时候，用4个字节表示，都是[-64,-18,-76,-77]，转为16进制都是[c0,ee,b4,b3],

    如果想将这些字符转换位字符串输出，差异出现了，假如用GB2312构建字符串，则构建的字符串为“李闯”，如果用ISO 8859-1或Windows-1252标准构建，

   结果就是“Àî´³”。这是因为GB2312两个字节构建一次，0xc0ee在GB2312码表中就是“李”，而0xb4b3在GB2312码表中就是“闯”；而ISO 8859-1或
  
   Windows-1252是一个字节构建一次，0xc0在对应的码表中就是“À”，0xee对应的码表中就是“î”，0xb4在对应的码表中就是“´”，0xb3对应的码表中就是“³”
  
  iv.GB2312编码是第一个汉字编码国家标准，对所有收录字符进行了“分区”处理，共有94个区，每个区含有94个位，共有8836个码位
    这种方式也叫做“区位码”，具体分区情况可参见： 
    http://www.qqxiuzi.cn/zh/hanzi-gb2312-bianma.php
    http://www.qqxiuzi.cn/bianma/zifuji.php
    http://tools.jb51.net/table/gb2312
  v.GB2312只是编码表，区位码要转换为计算机编码还需要转换，首先按字节转换为16进制，然后各自加上0xA0。为了好计算16进制用二进制取代，举例如下：
    “李”在GB2312中是32区78号，高位“32”用二进制表示[0010 0000]，加上0xA0，即[1010 0000]，结果为[1100 0000]，十六进制就是0xc0;
		低位“78”用二进制表示[0100 1110]，加上0xA0，即[1010 0000]，结果为[1110 1110]，十六进制就是0xee
    “闯”在GB2312中是20区19号，高位“20”用二进制表示[0001 0100]，加上0xA0，即[1010 0000]，结果为[1011 0100]，十六进制就是0xb4;
 		低位“19”用二进制表示[0001 0011]，加上0xA0，即[1010 0000]，结果为[1011 0011]，十六进制就是0xb3
  vi.也可是通过字节流推断一个字符在GB2312编码表的哪个区中，举例如下：
    “老”0xC0CF，按字节分别减去0xA0，则高位为0x20，低位为0x2F，转化为十进制就是32与47，即“老”在GB2312码表中的32区47号；
    “马”0xC2ED，按字节分别减去0xA0，则高位为0x22，低位为0x4D，转化为十进制就是34与77，即“马”在GB2312码表中的34区77号
  vii.GB2312编码范围：A1A1－FEFE，其中汉字的编码范围为B0A1-F7FE，第一字节0xB0-0xF7（对应区号：16－87），第二个字节0xA1-0xFE（对应位号：01－94）。


6.GBK
  GBK是建立在GB2312的基础上，向下兼容GB2312。GBK在GB2312大概7000汉字的基础上，增加了一万四千多个汉字，将汉字总数增加到两万一千，其中包含繁体字
  码表可以参考：http://www.qqxiuzi.cn/zh/hanzi-gbk-bianma.php

  关于GBK编码，我们需要知道的重点是：
  i.GBK是GB2312的延续，GB2312编码是对字符用“区位码”分区处理的，汉字的区位号是16-87，每一个区位内部，横向与纵向都是0-9，但只使用了其中01-94位，
    区位码然后按字节加上0xA0就是GB2312编码了。
  ii.GBK的编码也是一块一块的，区位编号：81-FE，单个区位内，横向0-F，纵向4-F，除了7F和FF处是空出来外，其他的地方都是填满了的。
    GBK的区位码就是GBK的编码，不再需要转换了。
  iii.GBK与GB2312一样，高位字节都可以看做区码，低位字节都可以看做位码，区别仅仅是GB2312需要再用0xA0处理下
  iv.在GBK的低位字节中，最高位有可能为0，则有可能与ASCII码混淆，于是需要用特殊的策略，将GBK的低字节部分与ASCII区分开，具体是这样处理的：
    在设定是用GBK编码格式构建字符流后，在解析二进制字符流时，如果第一个字节的最高位为1，那么就将下一个字节读进来一起解析为一个汉字，
    而不用考虑此字节的最高位；解析完后，直接跳到第三个字节继续解析
  	

7.GB18030
  GB18030向下兼容GBK，是它的扩充版本，共有七万六千多个字符，包括了很多少数名族字符，以及中日韩同一字符
  用两个字节已经表示不了GB18030的所有字符，于是GB18030使用变长编码，有的字符是两个字节，有的字符是四个字节
  在两字节编码中，字节表示范围与GBK一致，在四字节编码中，第一三字节的值从0x81到0xFE，第二四字节的值从0x30到0x39

  注意：解析二进制时，看第二个字节的范围，如果是0x30到0x39，那就用四字节表示。而在GBK中，低位字节是从0x40开始的


8.Big5
  Big5是针对繁体中文的，主要用于台湾香港等地
  Big5包括一万三千多个繁体字，和GB2312类似，一个字符同样固定使用两个字节表示。
  在这两个字节中，高位字节范围是0x81-0xFE，低位字节范围是0x40-0x7E和0xA1-0xFE。
  
9.编码汇总
  ASCII码是基础，一个字节表示，最高位设置为0，其他7位表示128个字符，其他编码都是兼容ASCII的，最高位使用1来进行区分；
  西欧主要使用Windows-1252，使用一个字节，8位全部使用，总共256个字符；
  中国大陆主要使用GB2312,GBK,GB18030，字符越来越多，且后面兼容前面，除了GB18030有部分使用四字节外，其他都使用两字节；
  港台地区主要使用Big5；
  如果文本里的字符都是ASCII码字符，那么采用以上所说的任意编码方式都是一样的；
  但是如果有高位为1的字符，除了GB2312/GBK/GB18030外，其他的编码都是不兼容的，而这时就会出现乱码


10.初识乱码
  一个法国人，采用Windows-1252编码写了个文件，发给了一个中国人，中国人使用GB18030来解析这个字符，看到的就是乱码，举例：
  法国人发送的是“Pékin”，Windows-1252的二进制是（采用16进制）：50 E9 6B 69 6E，其中第二个字节“E9”对应“é”，其他
  都是ASCII码；
  中国人收到的也是这个二进制，但是把它看做GB18030编码，GB18030中E9 6B对应的是字符"閗"，于是他看到的就是："P閗in"，
  这看来就是一个乱码；
  反之也是一样的，就像GB2312中的举例一样，一个GB18030编码的文件如果被看做Windows-1252也是乱码；

  这样看来，之所以看起来是乱码，是因为看待或者说解析数据的方式错了。纠正的方法，只要使用正确的编码方式进行解读就可以了。
  切换查看编码的方式，并没有改变数据的二进制本身，而只是改变了解析数据的方式，从而改变了数据看起来的样子。

11.Unicode
  实际上，除了以上介绍的中文和西欧字符与编码，世界上还有许多别的国家的字符，都根据本国的需要，编制符合自身需要的字符编码表，
  每个国家的各种计算机厂商都对自己常用的字符进行编码，在编码的时候自然基本忽略了别的国家的字符和编码，
  这样造成的结果就是，出现了太多的编码，且相互不兼容。

  在这种情况下，国际社会集合起来，将世界上的所有字符统一编码，这就是Unicode。

  Unicode给世界上所有的字符都分配了一个唯一的数字编号，范围从0x000000到0x10FFFF，但大部分常用字符都在0x0000到0xFFFF之间，
  即65536个数字之内。每个字符都有一个Unicode编号，这个编号一般写成16进制，在前面加U+。
  大部分中文 的编号范围在U+4E00到U+9FA5，例如，"马"的Unicode是U+9A6C。

  Unicode就做了这么一件事，就是给所有字符分配了唯一数字编号。但是它并没有规定这个编号这么对应到二进制表示。
  其他编码都既规定了能表示哪些字符，又规定了每个字符对应的二进制是什么，而Unicode本身只规定了每个字符的数字编号是多少

  至于编号怎么对应到二进制表示，有多种方案，主要有UTF-8,UTF-16和UTF-32

  Unicode是字符集，UTF-8,UTF-16和UTF-32都是它的编码方式。
  Unicode其实只是一张巨大的编码表。要在计算机里面实现，也出现了几种不同的方案。也就是说如何表示unicode编码的问题。

  参考：http://www.qqxiuzi.cn/bianma/Unicode-UTF.php

12.UTF-32
  这个最简单，和Unicode码表基本一一对应，固定四个字节。
  但其实这种编码方式使用非常少，可以看出，每个字符都用四个字节表示，非常浪费空间。
  而我们使用的绝大部分字符都不会超过2个字节，这就导致了大量的浪费。
  
  总结：
    a.UTF-32统一用4个字节，简单倒是简单了，但是数据冗余确实太大了，以至于ABC之类一个字节可以搞定的字符都
    不得不使用4个字节表示，除了有用的部分，其他3个字节基本是被“0”填充了
    b.UTF-32实际采用比较少,我们的绝大部分汉字2个字节就可以搞定，用UTF-32就有两个字节是浪费的，浪费50%，所以UTF-16用的比较多；
    而在欧洲，绝大部分字符一个字节就可以搞定，用UTF-32就有三个字节是浪费的，浪费75%，所以用UTF-8的比较多


13.UTF-16
  基于UTF-32的缺点，UTF-16有优化，使用变长字节表示：能用两个字节表示，就用两个字节；两个字节搞不定，才用四个字节
  我们把Unicode unicode编码记作U，编码规则如下：
    a.如果U < 0x10000，也就是编码可以用16位表示，U的UTF-16编码就是U对应的16位无符号整数，16位正好2个字节1个字符，记作WORD
    b.如果U >= 0x10000,我们先计算U'=U-0x10000，然后将U'写成二进制形式，共20位，分成前后两段，yyyy yyyy yyxx xxxx xxxx
      U的UTF-16编码（二进制）就是：110110yyyyyyyyyy 110111xxxxxxxxxx
  
  例如：Unicode编码0x20C30，减去0x10000后，得到0x10C30，写成二进制是：0001 0000 1100 0011 0000。用前10位依次替代模板中的y，
  用后10位依次替代模板中的x，就得到：1101100001000011 1101110000110000，即0xD843 0xDC30。

  按照上述规则，Unicode编码0x10000-0x10FFFF的UTF-16编码有两个WORD，第一个WORD的高6位是110110，第二个WORD的高6位是110111。
  可见，第一个WORD的取值范围（二进制）是11011000 00000000到11011011 11111111，即0xD800-0xDBFF。
  第二个WORD的取值范围（二进制）是11011100 00000000到11011111 11111111，即0xDC00-0xDFFF    

  区分是两个字节还是四个字节表示一个符号，就看前两个字节的编号范围，如果是U+D800到U+DBFF，就是四个字节，否则就是两个字节

  对于编号在U+0000到U+FFFF的字符 (常用字符集），直接用两个字节表示，即一个WORD。Unicode编码的设计者将其中0xD800-0xDFFF保留下来,
  不对应任何字符，称其为代理区（Surrogate）

  字符值在U+10000到U+10FFFF之间的字符(也叫做增补字符集)，需要用四个字节表示。前两个字节叫高代理项，范围是U+D800到 U+DBFF
  高位替代就是指这个范围的码位是两个WORD的UTF-16编码的第一个WORD。低位替代就是指这个范围的码位是两个WORD的UTF-16编码的第二个WORD

  关于UTF-16，我们应该知道：
  i.编号在U+0000到U+FFFF的字符 (常用字符集），直接用此Unicode的两个字节表示；当然需要注意，两个字节的部分区域是无效区，
    不对应字符的。
  ii.对于编码0x10000-0x10FFFF的字符（增补字符集），换算后用四个字节表示。
  iii.那么，对于一个WORD，如何区分它是就是两个字节的，还是四个字节的一部分呢？直接看这两个字节的WORD的范围就可以了，
    如果范围是U+0000-U+D7FF或者U+E000-U+FFFF，那么这个WORD就是两个字节的，按两个字节解析就可以了；
    如果范围是U+D800-U+DB7F，那么这个WORD就是UTF-16编码的前两个字节，
    如果范围是U+DC00-U+DFFF，那么这个WORD就是UTF-16编码的后两个字节，两个WORD要联合解析
  iv.UTF-16常用于系统内部编码，UTF-16比UTF-32节省了很多空间，但是任何一个字符都至少需要两个字节表示，对于美国和西欧国家而言，
    还是很浪费的。


14.UTF-8
  UTF-8就是使用变长字节表示，每个字符使用的字节个数与其Unicode编号的大小有关，编号小的使用的字节就少，编号大的使用的字节就多
  具体来说，各个Unicode编号范围对应的二进制格式如下图所示：
	编号范围			二进制格式
	0x00-0x7F(0-127)		0xxx xxxx
	0x80-0x7FF(128-2047)		110x xxxx 10xx xxxx
	0x800-0xFFFF(2018-65535)	1110 xxxx 10xx xxxx 10xx xxxx
	0x10000-0x10FFFF ( >65535 )	1111 0xxx 10xx xxxx 10xx xxxx 10xx xxxx
  
  小于128的，编码与ASCII一样，最高位是0。其他编号的第一个字节有特殊意义，最高位有几个连续的1表示一共用几个字节表示，而其他
  字节都以10开头。
  对于一个Unicode编号，具体怎么编码呢？举例如下：
  “李”的Unicode编号是：0x674E，整数编号是26446，其对应的UTF-8二进制格式是：1110xxxx 10xxxxxx 10xxxxxx
  整数编号26446的二进制格式是 0110 0111 0100 1110
  将这个二进制位从右到左依次填入二进制格式中，取代原来的x,结果就是其UTF-8编码：11100110 10011101 10001110
  填完后，如果对应的二进制格式还有没填的x，则设为0
  16进制表示为：0xE69D8E

  关于UTF-8，我们需要知道以下几点：
  i.UTF-8是兼容ASCII的，表示ASCII码只用一个字节就可以搞定，而不必像UTF-16/32那样用2个甚至4个字节表示了；
  ii.欧美人喜欢用UTF-8，因为他们的符号大部分都可以用一个字节表示，相对于其他编码方式已经很节省空间了；
  iii.中国人不大喜欢用UTF-8，因为对于大部分中文而言，一个中文字符需要用3个字节表示，这相对于UTF-16或者GBK只要2个字节，开销就大多了。


15.Unicode小结
  Unicode给世界上所有字符都规定了一个统一的编号，编号范围达到了110多万，但大部分字符都在65536以内。
  Unicode本身没有规定怎么把这个编号对应到二进制形式，于是就有了UTF-8/16/32，由它们负者将Unicode编号对应到二进制形式，
  只是对应方法不同而已。
  UTF-32对应方法最简单，统一使用4个字节表示，Unicode码就是它的UTF-32二进制编码。
  UTF-16大部分使用2个字节表示，少部分使用4个字节表示。能够用2个字节表示的，直接用此Unicode的两个字节表示UTF-16的二进制码；
  不能用2个字节表示的，按照110110yyyyyyyyyy 110111xxxxxxxxxx的格式，填充进去数字即可。
  UTF-8使用1到4个字节表示，可以直接兼容ASCII，英文字符使用一个字节，中文字符大多使用3个字节。格式直接按照模板套即可。

  Unicode是一个字符编码表，UTF-8/16/32都是它的编码方式，这3种之外，不排除还有其他的编码方式。


16.编码转换
  有了Unicode之后，每一个字符就有了多种不兼容的编码方式，比如说“李”这个字，
  GB2312/GBK/GB18030	0xC0EE
  Unicode		0x674E
  UTF-8			0xE69D8E
  UTF-16/32		0x674E

  这几种格式之间可以借助Unicode编号进行编码转换,
  与前文提到的切换查看编码方式正好相反，编码转换改变了数据的二进制格式，但并没有改变字符看上去的样子。

  关于编码转换，我们需要知道以下几点：
  i.切换查看编码方式，并没有改变数据的二进制本身，而只是改变了解析数据的方式，从而改变了数据看起来的样子
  ii.编码转换改变了数据的二进制格式，比如说上面的“李”，在GBK系列字符码表中为0xC0EE，但是到了新的Unicode码表中，
    则用0x674E表示“李”这个字，这还仅仅只是码表的转换，具体到编码方式的转换，改变更多，像UTF-8/16都有自己独特的转换方式
    都要按照模板进行转换。虽然“李”这个字看上去没有改变，但它的二进制形式却已经改变了


17.再看乱码
  乱码出现的一个重要原因是解析二进制的方式不对，通过切换查看编码的方式就可以解决乱码问题；
  但如果怎么改变查看方式都不对的话，那很可能就不仅仅是解析二进制的方式不对，而是文本在错误解析的基础上还进行了编码转换。
  举例说明：
    a.两个字 "老马"，本来的编码格式是GB18030，编码是(16进制): C0 CF C2 ED。
    b.这个二进制形式被错误当成了Windows-1252编码， 解读成了字符 "ÀÏÂí"
    c.随后这个字符进行了编码转换，转换成了UTF-8编码，形式还是"ÀÏÂí"，但二进制变成了：C3 80 C3 8F C3 82 C3 AD，每个字符两个字节。
    d.这个时候，再按照GB18030解析，字符就变成了乱码形式"脌脧脗铆"， 而且这时无论怎么切换查看编码的方式，这个二进制看起来都是乱码。

  这种情况是乱码产生的主要原因

  这种情况其实很常见，计算机程序为了便于统一处理，经常会将所有编码转换为一种方式，比如UTF-8， 在转换的时候，需要知道原来的编码是什么，
  但可能会搞错，而一旦搞错，并进行了转换，就会出现这种乱码。这种情况下，无论怎么切换查看编码方式，都是不行的。
